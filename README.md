# 一、什么是人工智能

人工智能就其本质而言，是机器对人的息维或行为过程的模拟让它能像人一样思考或行动。根据输入信息进行模型结构、权重更新实现最终优化。特点:信息处理、自我学习、优化升级。

## 1.1 人工智能实现方法

- 机器学习（Machine Learning, ML）从数据中寻找规律、建立关系，根据建立的关系去解决问题的方法。从数据中学习并且实现自我优化与升级

  - 监督学习（Supervised Learning）：通过训练数据集（包含正确的结果）学习输入和输出之间的关系。
  - 无监督学习（Unsupervised Learning）：在没有标签的数据（包含不正确的结果）中寻找模式和结构。
  - 半监督学习（Semi-supervised Learning）：结合有标签和无标签的数据（少量的正确结果）进行学习。
  - 强化学习（Reinforcement Learning）：通过与环境的交互来学习如何做出决策。（根据结果收获的奖惩进行学习，如 AlphaGo）

- 深度学习（Deep Learning, DL）

  - 卷积神经网络（Convolutional Neural Networks, CNNs）：适用于图像识别和处理。
  - 循环神经网络（Recurrent Neural Networks, RNNs）：适用于序列数据和时间序列分析。
  - 长短期记忆网络（Long Short-Term Memory, LSTM）：一种特殊的 RNN，适合处理和预测时间序列数据。
  - 生成对抗网络（Generative Adversarial Networks, GANs）：通过生成器和判别器的对抗学习生成新的数据样本。

- 符号推理（Symbolic Reasoning）

  - 使用逻辑规则和符号操作来模拟人类推理过程。

- 进化算法（Evolutionary Algorithms）

  - 模仿自然选择和遗传机制来优化问题解决方案。

- 专家系统（Expert Systems）

  - 模拟专家的决策过程，通常基于规则引擎。根据既定逻辑和规则进行推理。无法处理新数据，无法学习新知识。

- 自然语言处理（Natural Language Processing, NLP）

  - 包括语言模型、情感分析、机器翻译等技术，使机器能够理解和生成自然语言。

## 1.2 机器学习和深度学习

- 包含关系：

  - 深度学习是机器学习的一个子集：深度学习是机器学习中的一种技术，专注于使用多层神经网络（即深度神经网络）来学习数据的复杂模式和特征。机器学习是一个更广泛的领域，包括了多种算法和方法，如决策树、支持向量机（SVM）、随机森林等。

- 数据和特征：

  - 机器学习：特征工程：在传统的机器学习中，通常需要人工提取特征，这需要领域知识和大量的工作。特征的好坏直接影响模型的性能。
  - 深度学习：自动特征提取：深度学习通过多层神经网络自动学习数据的高级特征，减少了对人工特征工程的依赖。

- 模型复杂度：

  - 机器学习：模型简单：传统的机器学习模型通常较为简单，易于理解和解释。
  - 深度学习：模型复杂：深度学习模型包含大量的参数和层，能够捕捉数据中的复杂和抽象的模式，但也更难解释。

- 数据需求：

  - 机器学习：数据量要求较低：传统的机器学习算法可以在较小的数据集上进行训练。
  - 深度学习：数据量要求较高：深度学习模型通常需要大量的数据来训练，以避免过拟合并提高性能。

- 计算资源：

  - 机器学习：计算资源要求较低：传统的机器学习算法可以在普通的计算机上运行。
  - 深度学习：计算资源要求较高：深度学习模型需要大量的计算资源，如 GPU，以加速训练过程。

- 应用领域：
  - 机器学习：广泛应用：机器学习技术被应用于各种领域，如金融、医疗、电商等。
  - 深度学习：特定领域：深度学习在图像识别、语音识别、自然语言处理等领域取得了显著的成果。

# 二、机器学习

y = 1000 \* 1.1^x

- 传统算法： 输入数据和算法，通过计算得到结果
- 机器学习：输入数据，计算机器通过学习得到算法，通过算法得到结果

## 2.1 什么是回归分析

回归分析是一种统计方法，用于研究因变量（目标变量）与一个或多个自变量（解释变量）之间的关系。回归分析的目标是建立一种数学模型，该模型可以预测因变量的值，基于自变量的值。

可以理解为数学中的模拟曲线，通过已知数据拟合出一条曲线（一个 y=f(x1,x2,x3...xn)），通过曲线预测未知数据

- 一元回归分析：只有一个自变量 y = f(x)
- 多元回归分析：有多个自变量 y = f(x1,x2,x3...xn)
- 线性回归分析：自变量和因变量之间的关系是线性的 y = ax + b
- 非线性回归分析：自变量和因变量之间的关系是非线性的 y = ax^2 + bx + c

## 2.2 监督学习之线性回归

目标值和特征值之前的差距尽可能小

M 是样本数量，y 是目标值，y'是预测值，1/2M 是权重， 2m 是方便求导，(y - y')^2 是误差

损失函数选择：min(1/2M \* ∑ \* ( y' - y )^2)

找到一个最合适的 a 和 b 使得损失函数最小

梯度下降法：通过不断调整 a 和 b 的值，使得损失函数的值逐渐减小，最终找到最优解。

梯度下降法的基本思想是：首先随机初始化模型参数，然后计算损失函数关于每个参数的梯度（即偏导数），接着沿着梯度的反方向（因为梯度指向最大增加的方向，所以要反方向）更新参数，以此来逐步逼近最小损失（找到损失函数的极小值）。（梯度越大说明 y 和 y'的误差越大）

min(1/2M \* ∑ \* ( y' - y )^2) = min(1/2M \* ∑ \* ( ax + b - y )^2) = f(a,b)

通过求偏导数，得到 a 和 b 的更新公式，然后不断迭代更新 a 和 b 的值，直到损失函数的值不再变化或者变化非常小。

### 2.2.1 步骤

1. 数据预处理：对数据进行清洗、归一化、特征选择等操作，以便于后续的模型训练。
2. 生成损失函数
3. 选择回归模型：选择适合的回归模型，如线性回归、多项式回归、岭回归等。
4. 训练模型：使用训练数据集对模型进行训练，通过梯度下降法等优化算法来调整模型的参数，使得损失函数的值最小。
5. 模型评估：使用测试数据集对模型进行评估，计算模型的准确率、MSE 均方误差，R 方值等指标，以评估模型的性能。
6. 模型预测：使用训练好的模型对新的数据进行预测，得到预测结果。

### 2.2.2 例子

- [单因子线性回归](/sl/line.py)
- [多音字线性回归](/sl/mutil.py)

## 2.3 监督学习之逻辑回归（分类问题）

在进行分类问题时吗，样板量变大后，使用线性回归模型，模型效果变差，可能的原因是什么？

1. 样本量变大后，模型复杂度增加，导致过拟合
2. 样本量变大后，模型训练时间增加，导致模型训练不稳定
3. 样本量变大后，模型训练数据分布发生变化，导致模型效果变差

二分类 f(x) = 1 / (1 + e^(-g(x))) = sigmoid(g(x))

- y = 1, sigmoid(g(x0)) > 0.5
- y = 0, sigmoid(g(x)) < 0.5

g(x) 可以是线性回归模型，也可以是多项式回归模型。 -g(x)也称为逻辑回归模型的决策函数(边界)。

损失函数选择

- -log(f(x)) 当 y = 1
- -log(1 - f(x)) 当 y = 0

则确定损失函数 J = -1/m \* ∑ \* ( y \* log(f(x)) + (1 - y) \* log(1 - f(x)) )

### 2.3.1 例子

- [逻辑回归](/sl/line.py)
